<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[strugee.net blog - 'development' category]]></title><description><![CDATA[strugee.net blog - 'development' category]]></description><link>https://strugee.net/blog/category/development</link><generator>stratic-indexes-to-rss</generator><lastBuildDate>Mon, 26 Feb 2018 04:23:30 GMT</lastBuildDate><atom:link href="https://strugee.net/blog/category/development/index.rss" rel="self" type="application/rss+xml"/><copyright><![CDATA[Â© Copyright 2012-2018 AJ Jordan. Available under the GNU Affero GPL.]]></copyright><webMaster><![CDATA[AJ Jordan <alex@strugee.net>]]></webMaster><item><title><![CDATA[Winter break retrospective & spring semester goals]]></title><description><![CDATA[<p>Tonight I'll have been back at college for a full week, and I wanted to write up a little retrospective of winter break to see what I accomplished (and in particular, which <a href="https://strugee.net/blog/2017/12/winter-break-priorities-2017-18">goals</a> I completed or missed).</p>
<p>You may wish to skip directly to the <a href="https://strugee.net/blog/#executive-summary">executive summary</a>.</p>
<h1>Resolved goal: Node.js manpage PR</h1>
<p>I didn't <em>complete</em> this goal per se, but I did at least resolve it <a href="https://github.com/nodejs/node/pull/14164#issuecomment-357909699">by closing the Pull Request</a>. I felt pretty bad about it (especially because I kept saying I intended to finish it) but honestly, it became clear to me that I'd just lost the motivation to keep going with it. I would love it if this was included in Node.js core, but I just consistently have higher priorities. So rather than leave it hanging and cluttering up the Pull Requests view, I just closed it to reflect reality. I made sure not to delete the branch though, in case someone (distant future me?) wants to pick it up again.</p>
<h1>Failed goal: deal with GPG keysigning</h1>
<p>I did nothing to push this goal forward. While I made <a href="https://strugee.net/blog/2018/01/improving-gpg-security">numerous improvements to my GPG setup</a>, I did not actually sign anyone's key, which was what this goal was about. This feels unfortunate. (I also do not have access to the private key material in college, and am <em>certainly</em> not about to ask that it be shipped to me.)</p>
<h1>Partially completed goal: push Debian packaging work forward</h1>
<p>There were two components to this: <a href="https://tracker.debian.org/pkg/profanity">Profanity packaging</a> upgrades and getting the new <a href="https://github.com/strugee/filter-other-days">filter-other-days</a> packaging into Debian. I made no progress on the Profanity packaging. However, I did <a href="https://github.com/strugee/dots/commit/2b477a7079de9ff675fd4e2d22f58938ffbb7bc9">fix a misconfiguration in my <code>.reportbugrc</code></a> (which annoyingly had previously sent my incredibly detailed email about Profanity packaging to <code>/dev/null</code>) and then submitted <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=886310">an ITP</a> (Intent To Package bug, which is a Debian thing) for filter-other-days. I then used that ITP bug number <a href="https://github.com/strugee/filter-other-days/commit/d09943c6ac4eea07720cc88596bed3594c3f4644">to fix the last <code>.deb</code> Lintian warning</a> (although see below). Then I paired with <a href="https://github.com/anjakefala">Anja</a> who is, as always, an angel, and we figured out the weirdness that is <code>dput</code> and <a href="https://mentors.debian.net/">mentors.debian.net</a>. Finally I was able to upload filter-other-days(!) BUT I was in for a rude awakening - apparently Lintian checks for <code>.deb</code>s and <code>.dsc</code>s are different. So while my binary package was Lintian-clean, my source package unfortunately wasn't. This is something I will need to work on in the weeks to come. That being said, I'm still pretty proud of what I've accomplished here! I've made significant progress on this front.</p>
<h1>Completed goal: lazymention v1</h1>
<p>One of the first things I did was ship lazymention 1.0.0 - and I wrote <a href="https://strugee.net/blog/2017/12/announcing-lazymention-elegant-outbound-webmention-for-static-sites">an announcement blog post</a> to accompany it! (In fact, I syndicated that blog post to <a href="https://news.indieweb.org/">IndieNews</a> <em>using lazymention</em>, which felt pretty damn awesome.) I got some great feedback on it from the IndieWeb community, and my <a href="https://lobste.rs/s/kip3yk/announcing_lazymention_elegant">lobste.rs submission</a> - which also got some great engagement - even made the front page, which was pretty unreal! I still have a lot more work to do with lazymention - in particular, it doesn't actually respect edits (so it'll resend Webmentions with every job submission) - but for now it works well. I'm super pleased with it, and have integrated it into my site deployment workflow. I even wrote <a href="https://github.com/strugee/ping-lazymention/">a module</a> so other people can do this, too!</p>
<h1>Failed goals: ActivityPub in pump.io core, pump.io PR review</h1>
<p>No progress on this front. I did start hacking on a <a href="https://github.com/pump-io/telemetry">telemetry server</a> which will eventually be helpful for our ActivityPub rollout, but that did not in any way <em>directly</em> help fulfill these goals. I also <a href="https://strugee.net/blog/2018/01/pump.io-5.1-stable-published-to-npm">released 5.1 stable</a>, but that's pretty routine by this point.</p>
<h1>Partially completed goal: two blog posts per week</h1>
<p>I stuck with this goal all the way up until the final week, where I didn't write any. (Although I wrote about my <a href="https://strugee.net/blog/2018/01/improving-gpg-security">GPG keys</a> around the time I actually flew back to college.) The first week, I wrote about <a href="https://strugee.net/blog/2017/12/shell-script-is-one-of-the-purest-forms-of-human-expression">my thoughts on shell script</a> and about <a href="https://strugee.net/blog/2017/12/announcing-lazymention-elegant-outbound-webmention-for-static-sites">lazymention</a>; the second, I wrote about the <a href="https://strugee.net/blog/2018/01/pump.io-5.1-stable-published-to-npm">pump.io 5.1 stable release</a> and about <a href="https://strugee.net/blog/2018/01/tell-your-pr-reviewers-theyre-wrong">talking to Pull Request reviewers if you think they're wrong</a>.</p>
<h1>Failed stretch goal: paper editing</h1>
<p>I did absolutely no editing on the paper I intend to get published (which I originally wrote for a writing class). This was a stretch goal though, so that's totally fine.</p>
<h1>Additional activity: steevie maintenance</h1>
<p>After I finally found the cable I needed, I swapped out the cable that connects steevie's motherboard with the drives' SATA ports. This seemed to significantly improve disk performance, although there are still noticeable performance problems. I'm very, <em>very</em> happy to have finally gotten this done.</p>
<h1>Additional activity: Tor relay migration from Amazon EC2 to DigitalOcean</h1>
<p>After getting some advice on <a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-relays">tor-relays</a>, I <em>finally</em> sat down and looked into moving my relay away from Amazon Web Services. This is because AWS bills by usage, which for a Tor relay ends up being incredibly inefficient. It turned out to actually be way easier than I thought, which only served to make me mad that I hadn't done it sooner. In any case, I now save approximately $240/year AND I can push 1000GB/month as opposed to the 10GB/month I pushed before. In the words of <a href="https://github.com/strugee/torrc/commit/8b9fe85378adc834b8b7a9953de45f508b76bc3e">the commit where I made this change</a>: "this change made possible by the fact that I'm no longer getting billed up the wazoo by Amazon Web Services." Here's a of <a href="https://atlas.torproject.org/#details/C3CFCC9B5993A6F0D1349858C598C4A78AFE51F9">a Tor Metrics graph</a> (captured today) that shows the jump:</p>
<p><img src="/images/tor-relay-graph.svg" alt="Tor Metrics graph"></p>
<p>Anyway, I'm super happy I can contribute more to the Tor network <em>and</em> save lots of money in the process. That being said I am pretty damn salty I didn't realize this in the four <em>years</em> I've been running a Tor relay.</p>
<h1>Additional activity: offandonagain.org maintenance</h1>
<p>After turning on <a href="https://nodesecurity.io/">NodeSecurity</a> monitoring for <a href="https://offandonagain.org">offandonagain.org</a>, I found out that the module that underlies it, <a href="https://github.com/strugee/node-serve-random">node-serve-random</a>, had some vulnerable dependencies. Not only did I fix this, I wrote a large test suite for the module and found (and fixed!) <a href="https://github.com/strugee/node-serve-random/blob/master/CHANGELOG.md#200---2018-01-13">several bugs</a> in the process. Writing a test suite also allowed me to turn on <a href="https://greenkeeper.io/">Greenkeeper</a> for the module, which will be a huge help to me in keeping the module up-to-date.</p>
<h1>Additional activity: Stratic work</h1>
<p>First off, I released <a href="https://github.com/straticjs/generator-stratic/blob/master/CHANGELOG.md#100-beta-7---2017-12-3">beta 7</a> of <a href="https://github.com/straticjs/generator-stratic">generator-stratic</a>! Nothing major, just some polishing stuff. Stratic is getting very close to the point where I might want to start promoting it more aggressively, or declaring it stable, and (with a <em>lot</em> of super-helpful feedback from my family) I worked on something that's super important before we get there: <a href="https://github.com/straticjs/RFCs/issues/22">a logo</a>!</p>
<p>Here are two of my favorites so far:</p>
<div class="two-image-container">
<p><img src="/images/stratic-logo-asteroid-with-pipe.svg" alt="Yellow background with a centered black file icon and a asteroid coming up from earth in the midddle and a pipe to the right"> <img src="/images/stratic-logo-rocket-with-pipe.svg" alt="Yellow background with a centered black file icon and a rocket coming up from earth in the midddle and a pipe to the right"></p>
</div>
<p>These are based off the JS logo, in case you hadn't seen it before:</p>
<p><img src="/images/js-logo.svg" alt="Black JS text in the bottom-right corner of a yellow background"></p>
<p>Anyway, I have to post another iteration in the <a href="https://github.com/straticjs/RFCs/issues/22">GitHub issue</a> based on some feedback from <a href="http://saul.pw/">Saul</a> (who I had a lovely lunch with) - he thinks I should reverse it so the pipe is on the left, so it looks like the file is coming out of the pipe. But anyway you should comment there if you have feedback!</p>
<h1>Additional activity: IndieWeb stuff</h1>
<p>I attended Homebrew Website Club in San Fransisco, which was <em>incredible</em>. I got to meet a bunch of new people, as well as say hi to <a href="http://snarfed.org/">Ryan</a> and <a href="http://tantek.com/">Tantek</a> again, which was so nice - it's always just <em>better</em> to talk in real life. Tantek said (at least if I recall correctly) that my laptop was one of the best-stickered laptops he'd ever seen, which made me feel just unbelievably special. He also gave me a <a href="http://microformats.org/">microformats</a> sticker (and helped me figure out where to put it), which I had on my old laptop and had been really missing, as well as a <a href="https://letsencrypt.org/">Let's Encrypt</a> sticker. The latter was so special I elected to put it on the inside of my laptop, which I reserve only for <em>really</em> special things (basically a <a href="https://www.recurse.com/">Recurse Center</a> refucktoring sticker and a sticker of <a href="https://github.com/SwartzCr">Noah</a> in <a href="https://www.eff.org/encrypt-the-web">this video</a>, which he handed to me like a business card the first time we met). Anyway, every time I look at the Let's Encrypt sticker I just feel so happy. I love Let's Encrypt so damn much.</p>
<p>Homebrew Website Club was super inspiring, so when I got back to where I was staying (at my mom's boyfriend's house) I started implementing an <a href="https://indieweb.org">IndieWeb</a>-style social stream for strugee.net. It still needs some polishing but is actually pretty close to being done. Who knows when I'll have time to finish it, but it's getting there! I'm so freaking excited, honestly. Also, I added proper timestamp mf2 metadata to my site, as well as a visual display for post edits, and I expanded what type of Webmentions the display code recognizes too!</p>
<!-- TODO nuke this when I actually do proper header anchors -->
<p><span id="executive-summary"></span></p>
<h1>Executive summary</h1>
<p>I resolved or completed 2 goals, partially completed 2 goals, failed 3 goals, and failed 1 stretch goal. Additionally I did significant work in 5 other areas. Out of the goals I set for myself, I completed 51% (Debian packaging work is ~2/5 complete; blog posts were written 2/3 of the time); not counting the stretch goal, I completed 61.2%. I'm pretty happy with what I got done during this period; however, while I was productive, the numbers show that I did a mediocre job sticking to my goals. In the future I should focus on making more realistic goals and then sticking to them (though not too much - it is a break, after all!).</p>
<p>Speaking of which, partway through break I felt like I was on the edge of burnout, which to me was a <em>very</em> clear sign that I was pushing myself way too hard during a time I should have been unwinding. Because of that I cut what I was doing a <em>lot</em>, which helped pretty dramatically. In fact, I think without that I wouldn't have been able to do some of the later stuff, like all the IndieWeb work. So that's another reason I have to find a way to balance sticking to goals and just relaxing (which doesn't necessarily mean not coding, just doing whatever coding I feel like in the moment) - I feel like I was pushing myself too hard to meet my goals (and then getting distracted and not meeting them) and that's what led to the feeling. Obviously there are different constraints for e.g. schoolwork; here I'm referring <em>only</em> to free time like breaks.</p>
<h1>Spring semester goals</h1>
<p>With that in mind, I want to set some very broad goals for spring semester. I may update this list as time goes on, but for now I have four overarching goals I want to accomplish (besides the usual day-to-day code maintenance stuff):</p>
<ul>
<li>Finish editing the paper I wrote last semester on freedom-respecting software and intersectionality, and get it published</li>
<li>Make <em>some</em> measurable progress on my <a href="https://github.com/strugee/draft-webpush-2fa">Push-based Two-factor Authentication IETF draft</a></li>
<li>Get access to the University of Rochester darkroom and start developing/printing photos again</li>
<li>Start pushing the University of Rochester library (and <em>maybe</em> the journalism department?) to start adopting Tor technologies</li>
</ul>
<p>I'm excited to see how it goes!</p>
]]></description><link>https://strugee.net/blog/2018/01/winter-break-retrospective</link><guid isPermaLink="true">https://strugee.net/blog/2018/01/winter-break-retrospective</guid><category><![CDATA[personal]]></category><category><![CDATA[development]]></category><category><![CDATA[blaggregator]]></category><pubDate>Tue, 23 Jan 2018 20:51:03 GMT</pubDate></item><item><title><![CDATA[pump.io 5.1 stable published to npm]]></title><description><![CDATA[<p>Last night I officially published pump.io 5.1 to npm as a stable release!</p>
<p>As I wrote in the beta announcement, this release contains a variety of improvements:</p>
<ul>
<li><a href="https://strugee.net/blog/2017/08/zero-downtime-restarts-have-landed">Zero-downtime restarts</a>, which allows administrators to seamlessly roll over to new configurations and codebases</li>
<li>The daemon now generates startup log warnings on bad configurations, including insecure <code>secret</code> values and internal parameters</li>
<li>An official <code>Dockerfile</code> is now included with the release</li>
<li>The logged-out mobile homepage's menu icon is no longer incorrectly styled as black</li>
<li>An authorization problem with SockJS connections has been fixed</li>
</ul>
<p>5.1 stable <em>does</em> include one change the beta didn't: a bump to the version of the <code>gm</code> npm package which we depend on. This bump was done as a precautionary measure, as previous versions of <code>gm</code> depended on a version of the <code>debug</code> module which was vulnerable to denial-of-service security bugs.</p>
<p>As a project, we addressed these bugs <a href="https://strugee.net/blog/2017/10/denial-of-service-security-fixes-now-available">back in October</a> when we issued security releases for all supported release branches, and at the time we confirmed that the vulnerable function wasn't used by <code>gm</code>. Today's <code>gm</code> bump does <em>not</em> constitute a security release; instead, we're just bumping the version as a precautionary measure in case we missed something in October's assessment of the situation.</p>
<p>Aside from the <code>gm</code> bump, there are (as usual) miscellaneous version bumps included in this release. We've also started tracking test suite coverage information as well as overhauled our <a href="https://pumpio.readthedocs.io/">documentation on ReadTheDocs</a>, moving most of the in-repository documentation there.</p>
<p>If you want even more details of this release, you can also check out <a href="https://github.com/pump-io/pump.io/blob/master/CHANGELOG.md#510---2018-01-05">the changelog</a>.</p>
<p>pump 5.1 is a drop-in replacement for 5.0. That means if you're using our recommended installation method and installing from npm, you can upgrade with <code>npm install -g pump.io@5.1</code>. If you have a source-based install, you should merge and/or switch to the <code>v5.1.0</code> tag. And as always, if you encounter any problems, please feel free to reach out to the <a href="https://github.com/pump-io/pump.io/wiki/Community">community</a> or <a href="https://github.com/pump-io/pump.io/issues">file bugs you find</a>.</p>
<p>Finally, I would be remiss if I didn't point out that pump.io has a <strong>brand-new announcement mailing list</strong>! While the blog is great for announcing new releases, not everyone finds it convenient to check. Also, if we issue new betas in the middle of a release cycle, these aren't typically announced on the blog. Therefore in the future <em>all</em> new releases will be announced on the mailing list, not just initial betas. If you want to subscribe to the mailing list, you may do so <a href="https://lists.strugee.net/mailman/listinfo/pumpio-announce">here</a> - you'll get announcements of new features only, not e.g. feature announcements as seen on this blog. I hope people find this service useful!</p>
]]></description><link>https://strugee.net/blog/2018/01/pump.io-5.1-stable-published-to-npm</link><guid isPermaLink="true">https://strugee.net/blog/2018/01/pump.io-5.1-stable-published-to-npm</guid><category><![CDATA[pump.io]]></category><category><![CDATA[development]]></category><category><![CDATA[releases]]></category><category><![CDATA[blaggregator]]></category><pubDate>Sat, 06 Jan 2018 04:09:43 GMT</pubDate></item><item><title><![CDATA[Announcing lazymention: elegant outbound Webmention for static sites]]></title><description><![CDATA[<p>Last night I hit publish on version 1.0.0 of a new project, <a href="https://github.com/strugee/lazymention">lazymention</a>! Whoohoo!</p>
<p>tl;dr: lazymention exists to add Webmention support to static sites!</p>
<p>To elaborate a little bit, I developed lazymention because I had a problem with this site: I wanted to send outbound <a href="https://indieweb.org/Webmention">Webmentions</a> when I link to things, but my website is completely static. (Webmention, in case you didn't know, is a way to notify another website that you linked to them, so the other website can display some UI about your reply or whatever.) The page builds happen on my local machine, not on the server. One option would be to just send Webmentions from my local machine too, but this isn't really a good solution for a couple reasons. First, I couldn't do it automatically at build-time because the built pages wouldn't have been deployed to the server yet, so receivers of my Webmentions would reject the mentions due to the source being nonexistant. That meant that I would have to have a separate step, which wouldn't really be <em>that</em> big of a deal (lazymention reqires pinging a server too) except for the second reason: I would need some way to keep track of where I'd already sent Webmentions to, and that would require synchronizing across computers. Probably the only decent way to do that would be to check it into Git, but having a program's data store checked in right next to the source code just feels kinda ugly. Plus, then it can't be shared with other people as a service.</p>
<p>So instead of doing it locally, I elected to build a server instead. Here's how it works: you mark up your stuff with <a href="https://indieweb.org/h-feed"><code>h-feed</code></a> and <a href="https://indieweb.org/h-entry"><code>h-entry</code></a>, and whenever anything happens (e.g. you publish a new blog post or whatever), you ping lazymention with the URL (either the feed or the post itself). lazymention will use your microformats2 markup to find the canonical location for a given post, then it will find all the links in the post and send Webmentions for them. And presto! You've just sent Webmentions for your blog. lazymention also records when it's sent mentions, so if you ping it again, nothing will happen unless you've updated your content. I'm also planning to add <a href="https://indieweb.org/WebSub">WebSub</a> support to lazymention, too, and that'll work in the exact same way.</p>
<p>lazymention is super easy to get started with, especially because I've provided thorough documentation in the <a href="https://github.com/strugee/lazymention/blob/master/README.md">README</a>. If you find anything that's confusing or missing, please let me know by <a href="https://github.com/strugee/lazymention/issues/new">filing an issue</a>! I'd love to get it fixed. In fact, I'd be thrilled to hear about both positive <em>and</em> negative installation experiences.</p>
<p>Oh, and one more thing - lazymention is reusable in other applications. If you're writing a Node.js app and want to reuse its HTTP API, you can use its embedding API to get at the Express application and <code>Router</code> used internally. I'm not sure if people will actually find this useful, but I wrote it just for kicks anyway. See <a href="https://github.com/strugee/lazymention/blob/master/README.md#embedding">the embedding documentation</a> for more!</p>
<p>Cheers, and happy mentioning! Elegant outbound Webmention for static sites is here.</p>
]]></description><link>https://strugee.net/blog/2017/12/announcing-lazymention-elegant-outbound-webmention-for-static-sites</link><guid isPermaLink="true">https://strugee.net/blog/2017/12/announcing-lazymention-elegant-outbound-webmention-for-static-sites</guid><category><![CDATA[development]]></category><category><![CDATA[indieweb]]></category><category><![CDATA[releases]]></category><category><![CDATA[blaggregator]]></category><pubDate>Fri, 29 Dec 2017 18:52:04 GMT</pubDate></item><item><title><![CDATA[Webmention test post]]></title><description><![CDATA[<p>Once again I need to test whether <a href="https://github.com/strugee/lazymention">lazymention</a> - and more importantly, the underlying libraries (<a href="https://github.com/strugee/node-send-webmention">node-send-webmention</a> and <a href="https://github.com/strugee/node-get-webmention-url">node-get-webmention-url</a>) - complies with the <a href="https://www.w3.org/TR/webmention/">W3C spec</a>. I'll be using <a href="https://webmention.rocks/">webmention.rocks</a>, so, here's a large list of links:</p>
<p><a href="https://webmention.rocks/test/1">Test 1</a>, <a href="https://webmention.rocks/test/2">Test 2</a>, <a href="https://webmention.rocks/test/3">Test 3</a>, <a href="https://webmention.rocks/test/4">Test 4</a>, <a href="https://webmention.rocks/test/5">Test 5</a>, <a href="https://webmention.rocks/test/6">Test 6</a>, <a href="https://webmention.rocks/test/7">Test 7</a>, <a href="https://webmention.rocks/test/8">Test 8</a>, <a href="https://webmention.rocks/test/9">Test 9</a>, <a href="https://webmention.rocks/test/10">Test 10</a>, <a href="https://webmention.rocks/test/11">Test 11</a>, <a href="https://webmention.rocks/test/12">Test 12</a>, <a href="https://webmention.rocks/test/13">Test 13</a>, <a href="https://webmention.rocks/test/14">Test 14</a>, <a href="https://webmention.rocks/test/15">Test 15</a>, <a href="https://webmention.rocks/test/16">Test 16</a>, <a href="https://webmention.rocks/test/17">Test 17</a>, <a href="https://webmention.rocks/test/18">Test 18</a>, <a href="https://webmention.rocks/test/19">Test 19</a>, <a href="https://webmention.rocks/test/20">Test 20</a>, <a href="https://webmention.rocks/test/21">Test 21</a>, <a href="https://webmention.rocks/test/22">Test 22</a>, <a href="https://webmention.rocks/test/23/page">Test 23</a></p>
<p>Hopefully it works \o/</p>
]]></description><link>https://strugee.net/blog/2017/11/webmention-test-post</link><guid isPermaLink="true">https://strugee.net/blog/2017/11/webmention-test-post</guid><category><![CDATA[development]]></category><pubDate>Fri, 24 Nov 2017 20:24:46 GMT</pubDate></item><item><title><![CDATA[filter-other-days is portable to FreeBSD]]></title><description><![CDATA[<p>I'm pleased to announce <code>filter-other-days</code> 1.0.1. This is a bugfix release primarily improving portability to other Unix-like operating systems; in particular, the test suite now fully passes under FreeBSD. Specifically:</p>
<ul>
<li>Various portability bugs in the test suite itself were fixed - the test suite no longer relies on a GNU <code>date</code> (with GNU <code>date -d</code> semantics) or a fully-functional <code>/dev/fd</code> (the fallback option is named pipes), and it doesn't hardcode bash's install path as <code>/bin/bash</code></li>
<li>Some non-portable uses of <code>echo "\n"</code> which break under BSD systems were replaced with <code>printf</code> invocations</li>
<li>Travis CI now checks <code>filter-other-days</code> with Debian's <code>checkbashisms</code> script, which is run in strict mode</li>
<li>Non-portable uses of <code>test</code>'s <code>-o</code> option were caught by <code>checkbashisms</code> and replaced with <code>||</code></li>
</ul>
<p>With these changes I expect that <code>filter-other-days</code> will probably run on all major BSD distributions. I intend to confirm this hypothesis soon and have filed bugs for <a href="https://github.com/strugee/filter-other-days/issues/12">OpenBSD</a> and <a href="https://github.com/strugee/filter-other-days/issues/13">NetBSD</a>, plus <a href="https://github.com/strugee/filter-other-days/issues/14">illumos</a> just for kicks.</p>
<p>As with 1.0.0, you can clone <code>filter-other-days</code> <a href="https://github.com/strugee/filter-other-days">from GitHub</a> or you can download a (signed) <a href="https://github.com/strugee/filter-other-days/releases/tag/v1.0.1">tarball</a>. Please do <a href="https://github.com/strugee/filter-other-days/issues/new">report any bugs</a> you find in the release.</p>
<p>Enjoy!</p>
]]></description><link>https://strugee.net/blog/2017/11/filter-other-days-is-portable-to-freebsd</link><guid isPermaLink="true">https://strugee.net/blog/2017/11/filter-other-days-is-portable-to-freebsd</guid><category><![CDATA[development]]></category><category><![CDATA[releases]]></category><category><![CDATA[sysadmin]]></category><category><![CDATA[blaggregator]]></category><pubDate>Wed, 01 Nov 2017 20:39:53 GMT</pubDate></item><item><title><![CDATA[filter-other-days: Artificial Ignorance-compatible logfile date filtering]]></title><description><![CDATA[<p>I've just published version 1.0 of my latest project, <code>filter-other-days</code> - a shell script to filter logfiles for today's date in an Artificial Ignorance-compatible way.</p>
<p>If you haven't heard of <a href="http://www.ranum.com/security/computer_security/papers/ai/index.html">Artificial Ignorance</a>, it's something you should look into cause it's pretty awesome. Here's the tl;dr: it doesn't make sense to look for all the "interesting" things  in logfiles, because it's not actually possible to enumerate all the failure conditions of a system. So instead what we do is <em>throw away</em> entries that we're <em>sure</em> are just routine. Since we've gotten rid of all the uninteresting entries, whatever is left has to be interesting.</p>
<p>I find this pretty compelling, and decided to start implementing it on my Tor relay. I quickly realized that my ideal workflow would be to configure cron to send me email with a daily report of interesting log entries. However, this presented a problem: how to get just today's log entries? I wanted to be able to handle all logfiles at once instead of receiving different reports for different logs, so I had to be able to parse all logfiles in the same way. My relay runs on FreeBSD, so the logs are unstructured text files, and even worse, several daemons (like Tor itself) write timestamps in a different format - this makes parsing all logfiles at once super difficult because I couldn't just trivially <code>grep</code> for today's date since that would end up dropping legitimate entries from logfiles that formatted their timestamps differently.</p>
<p>I briefly considered trying to write a regex to match all sorts of different timestamp formats, but quickly rejected this idea as too fragile. There are a lot of moving parts in a modern operating system - what if e.g. a daemon changed its defaults about how to format timestamps? Or, more likely, what if I simply missed a particular format present in my logs? Then I'd be accidentally throwing away an entire logfile. To solve this problem, I decided to apply the same idea behind Artificial Ignorance - if I couldn't reliably, 100% match log entries from today's date, I could do the next best thing and attempt to discard all entries from <em>other</em> dates. In this case the worst that could happen is me recieving irrelevant information, and I'd be basically guaranteed to never miss an legitimate entry from today.</p>
<p><code>filter-other-days</code> is a working implementation of this design. Originally I put it with the other random scripts I keep with my <a href="https://github.com/strugee/dots/tree/master/bin">dotfiles</a>, but it quickly became obvious that it was useful as a standalone project. So I <a href="https://github.com/strugee/dots/commit/7dd7e2755c55194cdff1c7b24b24bca72581e346">extracted</a> it into its own repository, which now lives <a href="https://github.com/strugee/filter-other-days">on GitHub</a>. From there I continued to improve the script while adding a test suite and writing extensive documentation (including a Unix manpage - I always feel like a wizardly hacker when writing those things). This took, by my estimation, somewhere between 10 and 15 hours because this is actually a shockingly non-trivial problem, but mostly because regexes are hard.</p>
<p>But today I finally finished! So I'm super excited to announce that version 1.0 of <code>filter-other-days</code> is now available. You can either clone it from GitHub or download a <a href="https://github.com/strugee/filter-other-days/releases/tag/v1.0.0">tarball</a> (and the accompanying signature, if you want). It works pretty well already, but I have some ideas for future directions the project could go:</p>
<ol>
<li>Logic allowing you to actually specify the date you want to filter for, instead of assuming it's today (though you actually can already get this behavior using <code>faketime</code>; that's what the test suite does)</li>
<li>Removal of the dependency on GNU <code>seq</code> - this is, to my knowledge, the only non-POSIX requirement of <code>filter-other-days</code></li>
<li>Debian package, maybe?</li>
<li>More log formats (please <a href="https://github.com/strugee/filter-other-days/issues">report bugs</a> if you have formats <code>filter-other-days</code> doesn't recognize - which you probably do!)</li>
</ol>
<p>If you find this project useful, let me know! I'd love to hear about how people are using it. Or if it breaks (or doesn't fill your usecases), please <a href="https://github.com/strugee/filter-other-days/issues">report bugs</a> or send patches - I love those, too! Either way, may the logs be with you!</p>
]]></description><link>https://strugee.net/blog/2017/10/announcing-filter-other-days</link><guid isPermaLink="true">https://strugee.net/blog/2017/10/announcing-filter-other-days</guid><category><![CDATA[development]]></category><category><![CDATA[security]]></category><category><![CDATA[sysadmin]]></category><category><![CDATA[releases]]></category><category><![CDATA[blaggregator]]></category><pubDate>Fri, 20 Oct 2017 19:19:51 GMT</pubDate></item><item><title><![CDATA[pump.io denial-of-service security fixes now available]]></title><description><![CDATA[<p>Recently some denial-of-service vulnerabilities were discovered in various modules that pump.io indirectly depends on. I've bumped Express and <code>send</code> to pull in patched versions, and I've updated our fork of <code>connect-auth</code> to require a patched version of Connect, too. The remaining vulnerabilities I've confirmed don't affect us.</p>
<p>Because of these version bumps, I've just put out security releases which all administrators are encouraged to upgrade to as soon as possible. A semver-major release (5.0.0) was released within the past 6 months so per our <a href="https://github.com/pump-io/pump.io/wiki/Security">security support policy</a> this means there are three new releases:</p>
<ol>
<li>pump.io 5.0.2 replaces 5.0.0 and is available now on npm</li>
<li>pump.io 4.1.3 replaces 4.1.2 and is available now on npm</li>
<li>pump.io 4.0.2 will replace 4.0.1 <strike>and is currently undergoing automated testing (it'll be on npm shortly)</strike> <strong>Update:</strong> pump.io 4.0.2 is now on npm</li>
</ol>
<p>As these are security releases we encourage admins to upgrade as soon as possible. If you're on 5.0.0 installed via npm - our recommended configuration - you can upgrade by issuing:</p>
<pre><code>$ npm install -g pump.io@5
</code></pre>
<p>If you're on 4.1.3, you can upgrade by issuing:</p>
<pre><code>$ npm install -g pump.io@4
</code></pre>
<p>And when 4.0.2 is out, if you're on 4.0.1 you can upgrade by issuing:</p>
<pre><code>$ npm install -g pump.io@4.0
</code></pre>
<p>Note though that 4.1.3 is a drop-in replacement for 4.0.2, so you should consider just upgrading to that instead. Or even better, <a href="https://pumpio.readthedocs.io/en/latest/upgrades/4.x-to-5.x.html">upgrade to 5.x</a>!</p>
<p>If you don't have an npm-based install, you'll have to upgrade however you normally do. How to do this will depend on your particular setup.</p>
<p>As always, if you need help, you should get in touch with <a href="https://github.com/pump-io/pump.io/wiki/Community">the community</a>. I'd also like to specifically thank <a href="https://identi.ca/jxself">Jason Self</a>, who generously deployed a 24-hour private beta of these fixes on <a href="https://datamost.com/">Datamost</a>. One of the version bumps was ever-so-slightly risky, and being able to test things in production before rolling out patches for the entire network was invaluable. I wouldn't be as confident as I am in these releases without his help. So thanks, Jason - I really appreciate it!</p>
]]></description><link>https://strugee.net/blog/2017/10/denial-of-service-security-fixes-now-available</link><guid isPermaLink="true">https://strugee.net/blog/2017/10/denial-of-service-security-fixes-now-available</guid><category><![CDATA[pump.io]]></category><category><![CDATA[development]]></category><category><![CDATA[security]]></category><category><![CDATA[releases]]></category><category><![CDATA[blaggregator]]></category><pubDate>Sun, 01 Oct 2017 17:40:59 GMT</pubDate></item><item><title><![CDATA[How I accidentally started maintaining a social network with thousands of users]]></title><description><![CDATA[<p>As some of my readers (particularly Recursers) know, a couple of weeks ago I became an Invited Expert at the <a href="https://www.w3.org/wiki/Socialwg">Social Working Group</a> at the <a href="https://www.w3.org/">W3C</a> (World Wide Web Consortium). The W3C is a standards body. That means it's responsible for defining things like how things work on the web, such as how web pages are styled using CSS and how web developers can protect their apps from security vulnerabilities using <a href="https://www.w3.org/TR/CSP3/">Content Security Policy</a>.</p>
<p>My first thought when I got the email that my application had been accepted was, "<em><strong>WHOOOOOOOOO!</strong></em>" It was probably one of the most thrilling moments of my whole life. My second thought was, "how in the <em>world</em> did I get here!?" The truth is, it was almost an accident.</p>
<p>It started when I got involved in the <a href="http://pump.io">pump.io</a> project. pump.io, for those who haven't heard me talk about this endlessly (e.g. at RC), is a decentralized social network. That means that there can be multiple servers run by different people that are part of the social network, but the users on those servers can interact with each other in just the same way they could if it was just one big centralized server[1]. I first got involved in the pump.io project in August 2015. I was experimenting with different social networking software and decided to <a href="https://pump.strugee.net/">deploy</a> pump.io on my server. When I did I realized that pump... well, it didn't work very well. The web UI was kinda basic[2], everything was pretty buggy, and there were a lot of problems with the overall user experience. In fact, I know the exact day I set up pump.io (August 12th) because all throughout the experience <a href="https://github.com/pump-io/pump.io/issues/1093">I</a> <a href="https://github.com/pump-io/pump.io/issues/1094">was</a> <a href="https://github.com/pump-io/pump.io/issues/1095">filing</a> <a href="https://github.com/pump-io/pump.io/issues/1096">bugs</a> on things needing improvement. It was a shame, I thought, because this software seemed really neat. I thought it had a lot of potential.</p>
<p>After about two weeks it became clear that there was no activity in the upstream pump.io project. So after some deliberation, I ended up forking it (briefly). You can watch <a href="https://media.libreplanet.org/u/libreplanet/m/pump-io-the-federated-extensible-social-network/">this talk</a> around 16:00 to hear me talk about this a bit, though to be honest it's kind of just a footnote in the project's history. In the end Evan Prodromou, pump.io's author, ended up handing off some commit rights to community members.</p>
<p>Well, I thought, that was the end of that. Everything's smooth sailing from here on out! There were some big problems, though: the people who now had commit rights all were involved in other things and, more importantly, none of them knew JavaScript or Node.js! This makes me chuckle to this day, honestly.</p>
<p>So I started triaging issues. When people sent Pull Requests, I'd review them since it seemed like no one else was going to do it. <a href="https://github.com/pump-io/pump.io/pull/1114">#1114</a> was, as far as I can tell (or remember), the very first of these "unofficial" PR reviews. I kept going; I even reviewed Menno Vossen's <a href="https://github.com/pump-io/pump.io/pull/1136">epic PR which fixed all the tests</a> (fixing the tests being a feat which, having tried to start that work myself, I am to this day in awe of and <em>incredibly</em> thankful for). For that last one in particular, you'll note that <em>I</em> merged it, not Chris Webber. At some point in January(?), he asked me in <code>#pump.io</code> on IRC if I'd like write access to the repository, to which I said (paraphrased) "heck yes!" So he made it happen.</p>
<p>I never really intended for that to happen. However, I <em>was</em> the one doing almost all of the work. After a while it just made sense. This is what, among other things, I find so incredible about freedom-respecting software: you can just <em>do</em> things. I didn't ask anyone for permission to do those reviews. I just saw the need for a reviewer, and decided I'd help out.</p>
<p>Fast-forward to today, and I'm now an owner of the pump.io organization on GitHub. I make technical decisions about what to prioritize and what should go into pump.io core. I do a lot of the day-to-day work running the project, too, and setting up technical and policy infrastructure (with a lot of help from the community, of course, plus input from Evan). That, too, just made sense, as did my becoming an Invited Expert - I was pretty deeply engaged with the SocialWG's <a href="https://www.w3.org/TR/activitypub/">ActivityPub</a> specification already since it's based on the pump.io protocol, and I was really excited about said protocol being standardized. So I was participating pretty heavily and I think it just made sense to people in the Working Group for me to join. In fact, that also kinda happened by accident. I couldn't get edit access to the W3C wiki so we were speculating in <code>#social</code> on the W3C IRC server that it might be because I wasn't a "W3C member" or something. So some people at W3C were pinging the sysops team, etc., trying to mark me as a "trusted" user when someone - <a href="https://www.w3.org/People/Sandro/">Sandro Hawke</a>, I believe - said, "the other option is for you to just join the Working Group." To which I said, "well, but I'd have to join as an Invited Expert, and I don't think I qualify as an expert." Chris Webber's response? "You're just as much of an expert as me when I joined!"</p>
<p>tl;dr how in the world did I get here? I tried some software and got annoyed at it, so I just kind of <em>"did some stuff"</em> that led to me doing code reviews. That led to me getting involved in the decentralized social web which led to me <em>"doing some more stuff"</em> that got me involved in standards. Then because of that, I tried to edit a wiki and ended up being invited to apply as a W3C Invited Expert.</p>
<p>I mean, what the hell? Honestly. I can't emphasize enough that I didn't plan ANY of this. It just sort of... happened. And that, I think, is what's so cool about the free software community. It isn't about who you are, where you come from, or what your goals are. It's only about, do you show up? Do you show up and do awesome stuff?</p>
<p>I showed up, kind of by accident, and I now run a decentralized social network with thousands of users called pump.io.</p>
<p>What will happen if <em>you</em> show up?</p>
<p><em>Thanks so much to <a href="https://github.com/anjakefala">Anja</a> and <a href="http://jvns.ca/">Julia</a> for providing feedback on a draft version of this post.</em></p>
<p>[1]: I really hope this explanation makes sense and if it doesn't, I apologize - I use diagrams to explain this in real life.</p>
<p> [2]: Still is, but that should improve now that the technical debt work I've been focusing on for the past year is now <a href="https://strugee.net/blog/2017/03/express-4.x-in-pump.io-core">basically done</a>!</p>
]]></description><link>https://strugee.net/blog/2017/05/pump.io-accident</link><guid isPermaLink="true">https://strugee.net/blog/2017/05/pump.io-accident</guid><category><![CDATA[development]]></category><category><![CDATA[personal]]></category><category><![CDATA[pump.io]]></category><pubDate>Fri, 12 May 2017 19:51:53 GMT</pubDate></item><item><title><![CDATA[pump.io 4.0 in beta]]></title><description><![CDATA[<p>pump.io 4.0.0 is officially in beta! Whooo!</p>
<h1>Highlights</h1>
<p>This is a positively <em>huge</em> release, and I'm so excited to share it with the community. Some highlights:</p>
<ul>
<li>Express 4.x - I wrote about the significance of this change <a href="http://pump.io/blog/2017/03/express-4.x-in-pump.io-core">here</a>, but suffice to say that this significantly improves security, performance, and future maintainability</li>
<li>Performance and correctness improvements to the web UI's JavaScript</li>
<li>Better administrative experience, including the ability to specify configuration via environment variables</li>
<li>Better interoperability with the <a href="https://indieweb.org">IndieWeb</a></li>
</ul>
<h1>Upgrading</h1>
<p>The upgrade to Express 4.x and the improvements to configuration loading have the potential to break <em>some</em> existing pump.io installations, although 95% of installs should be completely unaffected. If you want to help test this beta, please set aside extra time as necessary to perform this upgrade - full documentation can be found on <a href="https://pumpio.readthedocs.io/en/latest/upgrades/3.x-to-4.x.html">ReadTheDocs</a>.</p>
<p>As always, this release will follow our normal <a href="https://github.com/pump-io/pump.io/wiki/Release-cycle">release cycle</a>, which means that the stable 4.0.0 release will go out in about a month.</p>
<h1>Test days</h1>
<p>Due to the complexity of this upgrade, we've decided to have some test days during the beta where we upgrade prominent nodes for a day, then downgrade them again. This will help expose problems earlier and make the upgrade smoother for everyone. So far Jason Self, who runs <a href="https://datamost.com/">Datamost</a>, has volunteered for this - if you're interested in joining him, please <a href="https://github.com/pump-io/pump.io/wiki/Community">get in touch</a>!</p>
<p>Happy hacking!</p>
]]></description><link>https://strugee.net/blog/2017/04/pump.io-4.0-in-beta</link><guid isPermaLink="true">https://strugee.net/blog/2017/04/pump.io-4.0-in-beta</guid><category><![CDATA[pump.io]]></category><category><![CDATA[development]]></category><category><![CDATA[releases]]></category><category><![CDATA[blaggregator]]></category><pubDate>Mon, 03 Apr 2017 17:03:10 GMT</pubDate></item><item><title><![CDATA[Getting on board with configuration management]]></title><description><![CDATA[<p>For a long while I've really disliked configuration management. This mostly stemmed from my experience <a href="https://github.com/strugee/steevie/blob/3069f53ee82c6b1709f22285b71ccdc0e5e0bced/apache-config/apache-config.pp">managing Apache via Puppet</a>, which I found indirect and unnecessary - the only reason I did this was basically to get version control. In fact, I even started a project called <a href="https://github.com/strugee/bindslash">bindslash</a> which I literally described as "not configuration management".</p>
<p>However, last Thursday, steevie (my primary server) crashed <em>again</em>. So I went into a fallback DigitalOcean VM I'd set up the last time this had happened and updated stuff. I presented my <a href="https://strugee.net/presentation-pumpio/libreplanet/">LibrePlanet slides</a> from that. And eventually I bit the bullet and set up a secondary email server which, to my great surprise, has not received a flood of spam yet (though I'm sure it will at some point).</p>
<p>The whole ordeal really made me understand the benefit of configuration management. I would've spent less time and been less stressed if I could just plug in a config management system to get a useful failover system. So as of today, I'm on board with configuration management, and bindslash is dead.</p>
<p>I still kinda hate Puppet, so I think I'll try out Ansible and <em>maybe</em> Chef. Ansible's agentless model in particular probably makes a lot of sense for my needs. It also makes me sad to kill bindslash, since I still think it would be a useful project and there's definitely a place for it in the world. But I no longer have any reason to work on it, so I'm just going to stop pretending I'll ever finish it. If anyone is interested in that approach, talk to me and I'll happily give you the name, the repo, my thoughts on its design, etc.</p>
<p>Anyway. Now to set up outbound mail on the failover VM.</p>
<p>*big sigh*</p>
]]></description><link>https://strugee.net/blog/2017/03/getting-on-board-with-configuration-management</link><guid isPermaLink="true">https://strugee.net/blog/2017/03/getting-on-board-with-configuration-management</guid><category><![CDATA[development]]></category><category><![CDATA[sysadmin]]></category><category><![CDATA[blaggregator]]></category><pubDate>Tue, 28 Mar 2017 16:59:56 GMT</pubDate></item><item><title><![CDATA[Express 4.x in pump.io core]]></title><description><![CDATA[<p>So I thought I'd take a moment to announce that the upgrade from Express 2.x to Express 4.x is <a href="https://github.com/pump-io/pump.io/pull/1208">finally complete</a>! I fixed up the last couple test failures last Wednesday, and the branch got merged on Thursday.</p>
<h1>A long time coming</h1>
<p>Believe it or not, the work to do this upgrade started almost an entire <em>year</em> ago. Express 2.x has been outdated and unmaintained for a long time now, so upgrading has been a high priority. However, it wasn't as simple as adjusting a version number - there were a staggering number of changes that needed to be made due to Express deprecating, removing, and changing things around. One of the most significant problems was the fact that the old template system that we used, utml, was not compatible with Express 3.x and above. That meant that we had to rewrite every single template into a modern language - an effort that resulted in <a href="https://github.com/pump-io/pump.io/pull/1170">over a thousand lines changed</a>!</p>
<p>However, the time for Express 4.x has finally arrived. With that and some other trivial version bumps, I'm proud to announce that pump.io is fully up-to-date in terms of dependencies with only three, non-critical exceptions. Whooooo!</p>
<h1>Immediate benefits</h1>
<p>There are a lot of reasons this is immediately awesome:</p>
<ol>
<li>Express 4.x fixes significant performance problems that existed in Express 3.x</li>
<li>Relatedly, Express 4.x fixes some security problems present in 3.x</li>
<li>The fact that our dependencies are <em>finally</em> up-to-date means that we can (and do!) now make use of <a href="https://greenkeeper.io/">Greenkeeper</a> and the <a href="https://nodesecurity.io/orgs/pumpio/projects/32213bb8-f9a6-4dd0-8fc6-5caa8ea5f8fc">Node Security Platform</a> to automatically track dependencies to make sure they're up-to-date and not introducing security vulnerabilities</li>
</ol>
<p>That last one is particularly significant. Greenkeeper and NSP will continuously monitor the project's dependencies and automate away a lot of the pain that's associated with keeping pump.io up-to-date. Everyone will get a more secure and stable codebase because of this setup.</p>
<h1>Looking forward</h1>
<p>The Express 4.x upgrade is a big change, and it's definitely possible that stuff has broken. We want to make sure that breakage doesn't make it into production. This change went into pump.io 4.0, which will go through our normal <a href="https://github.com/pump-io/pump.io/wiki/Release-cycle">release cycle</a>. That means it'll be in beta for a month before being released. As a part of that, <a href="https://jxself.org/">Jason Self</a> - who's kind enough to administer <a href="https://datamost.com/">Datamost</a> - has agreed to have a test day where Datamost upgrades to the beta for a day, then downgrade it again. This test day will give us much wider exposure than we would've gotten otherwise, which will be incredibly valuable feedback in the effort to identify and fix regressions. We haven't set a date yet, but if you'd like to join Jason in helping us find bugs, please get in touch with <a href="https://github.com/pump-io/pump.io/wiki/Community">the community</a>. We'd love your help.</p>
<p>Beyond the immediate release, though, there's still things to look forward to. Express 4.x gives us a better way to structure routing code, and a refactor to use this structure <a href="https://github.com/pump-io/pump.io/issues/1232">is planned</a>. There's a lot of room for improvement. But really, the most important benefit is this: technical debt is a far less pressing issue than before. That means that we can shift focus and spend more time fixing user-facing bugs, adding useful features, and generally improving the experience for our users. I couldn't be more excited.</p>
]]></description><link>https://strugee.net/blog/2017/03/express-4.x-in-pump.io-core</link><guid isPermaLink="true">https://strugee.net/blog/2017/03/express-4.x-in-pump.io-core</guid><category><![CDATA[pump.io]]></category><category><![CDATA[development]]></category><category><![CDATA[blaggregator]]></category><pubDate>Mon, 20 Mar 2017 16:22:27 GMT</pubDate></item><item><title><![CDATA[Default-secure systems]]></title><description><![CDATA[<p>So recently I presented on <a href="https://strugee.net/presentation-operational-security/">operational security</a> and then started in on the nightmare that is <a href="https://strugee.net/presentation-https-deployment/">HTTPS deployment</a>. And like I did with <a href="https://strugee.net/blog/2017/01/new-programming-language-part-i-handlers">language-level security</a> (I <em>still</em> need to write part 2 of that post), I thought to myself, this is so difficult. Why isn't there something that will do this for me? That's what my latest project is.</p>
<p>Here's the tl;dr:</p>
<pre><code>type(app)
=&gt; Django/Express.js/etc. app
secure_system(app)
=&gt; Docker image
</code></pre>
<p>Or in other words, you'll be able to take an existing web app that you've written, run it through this system, and it will spit out a complete, reasonably-secure system image.</p>
<p>Let's step back.</p>
<h1>The status quo</h1>
<p>Currently, when a developer wants to run a web app, they can either use something like Heroku, which is fully manged, or a VM from DigitalOcean or Amazon EC2 or something. There are a variety of reasons you might not want to use Heroku, but the only other option is a VM - and with a VM, you get a bare system where you have to set up everything from scratch. Lots of developers just don't have the operational experience to do this properly or securely, but it's not like they can go and get an operations team to do it for them. So they end up with systems that may have active security problems as well as little to no defense-in-depth mitigations for when security inevitably fails. Security is just another operational concern the developer has no time and no expertise to deal with, so it just doesn't happen. The developer spins up a VM, gets it to where it "works" and then moves on. <strong>This is not good enough.</strong></p>
<p>I don't want to create a false dichotomy, though: this is not the developer's fault. Everyone has conflicting priorities and it's unreasonable to expect the developer to spend lots of time learning to administrate systems so that they can then spend even more time, you know, administering systems. The problem is that there just isn't enough options available - we have to provide something better.</p>
<h1>A middle ground</h1>
<p>This is what my project is about: creating a middle ground between fully-managed deployment platforms and barebones, setup-from-scratch VMs.</p>
<p>This project rests on the idea that operational security (at least, in a single-server, single-admin context) flows from consistency, least privilege, and proactive, defense-in-depth security measures. Here are a couple core design goals:</p>
<ol>
<li>Meet developers where they are. Configuration management like Puppet is a great way to enforce consistency, but it adds a level of indirection and is just another thing that people running hobbyist projects don't have time to learn.</li>
<li>Tight integration with apps - this excludes more obscure types of web applications, but gives us a better footing to set up a solid deployment environment. It also may let us integrate more tightly with things like Content Security Policy in the future.</li>
<li>Support virtual hosting. The ability to run multiple apps while paying for a single VM is a compelling reason people go with VMs over e.g. Heroku - we won't be helping anyone if we leave this out.</li>
<li>Upgrades are optional. Any system image created by this project will present a system that is organized and can be maintained and modified by hand without breaking everything.</li>
<li>Upgrades are possible. Tight app framework integration will aid with putting data into well-known places that can be backed up and migrated to a new image generated by a newer version of this system.</li>
<li>Not designed for "real" production environments. Any project that has a dedicated operations person should not be using this; they should be rolling their own custom environments with something like Puppet. Accordingly, there won't be compromises in security in favor of flexibility - it's designed to cover 75% of cases "pretty well", which is still better than the status quo for smaller projects (almost 100% of cases don't have any security at all).</li>
</ol>
<p>I'd also like to highlight one really important decision: the output is complete system images. Probably at first this will mean Docker containers but this could easily be turned into VM images. This is a critical part of the design because it allows us to make broad, sweeping changes - for example, preferring system components written in memory-safe languages, replacing OpenSSL with LibreSSL, or creating systemd unit files that lock down service runtime environments to reduce the impact of a compromise. These improvements aren't possible unless we control the whole system. And because upgrades are optional but possible, the developer can get security improvements by "just" upgrading a component that they use, in the same way that they'd upgrade a library or something, as opposed to security being a continuous process they have to worry about. Again, obviously not perfect - but much better than the status quo.</p>
<p>I hope to have a MVP out Real Soon Nowâ¢. But in the meantime, if you have thoughts, feel free to reach out.</p>
]]></description><link>https://strugee.net/blog/2017/03/default-secure-systems</link><guid isPermaLink="true">https://strugee.net/blog/2017/03/default-secure-systems</guid><category><![CDATA[development]]></category><category><![CDATA[security]]></category><category><![CDATA[blaggregator]]></category><pubDate>Mon, 13 Mar 2017 15:59:17 GMT</pubDate></item><item><title><![CDATA[How I passed 2k GitHub contributions]]></title><description><![CDATA[<p>So the other day I logged into GitHub and saw something crazy:</p>
<p><img src="/images/github-2k-contributions.jpg" alt="Screenshot of my GitHub contribution graph showing 2,054 contributions over the past year"></p>
<p>How in the hell did I end up with that many contributions? Well, I think I know why - it happened because of a couple related, small habits I have. I thought I'd share them with everyone else as a sort of trivia - maybe you can adopt these habits too! (Although hopefully because you think they're good ideas, not because you just want to make yourself look cool on GitHub.)</p>
<h2>Fix typos</h2>
<p>If projects are freedom-respecting, that means that anyone is welcome to contribute if they're able to offer something valuable. How many times have you seen a typo in some docs? GitHub makes it super, super easy to fix these (just click the pencil icon in the upper-right of GitHub file views), and they're a fantastic way to contribute a little back to projects. Even if you aren't reading docs on GitHub, it often doesn't take that much time to find where they're hosted (which is frequently GitHub anyway). Really good docs will even have a link to their source right on the generated page.</p>
<p>So whenever I see a typo, I send a Pull Request. It's become an automatic response to seeing something that needs fixing, and is pretty routine for me nowadays.</p>
<p>Oftentimes there are changes that aren't as easy as a typo, but are still super easy to fix. Take <a href="https://github.com/Homebrew/brew/pull/1634">this Homebrew PR</a> - I authored it on a tablet and it took me under 3 minutes to make the suggested change[1]. That's not a lot of effort, and it'll help lots of people looking for the Homebrew change log. The next time you find yourself thinking "it kinda sucks that..." ask yourself - can I fix this myself? And if you can, go for it! Even if you screw up, I promise most projects will want to help you out instead of making fun of you[2] - as someone who runs several freedom-respecting projects, I know that getting new contributors is very, very valuable and because of that I'll do a lot to make contributing a good experience. I would encourage everyone to, as Mike McQuaid puts it in that Homebrew PR, "be the change you want to see in the world."</p>
<p> [1]: of course, that's partly because I'm pretty good at git and grok things like <code>rebase -i</code>. But even if that's not you and it would take you longer, it sounds like a great opportunity to improve your git skills to me!</p>
<p> [2]: I feel obligated to point out that not every project is like this - there are some projects that have a terrible culture (*coughcough*Linuxkernel*cough*). Screw them. They're not that common in my experience and it's their loss, anyway. Don't let them deter you from trying to improve things outside of their bubble of suck.</p>
<h2>File issues</h2>
<p>I just talked about making small changes whenever you see something you can improve with a couple minutes' time. But what if you're in a hurry, or it would take longer?</p>
<p>Filing issues is a super easy way to solve this. Get into the habit of filing issues for everything that irks you[3] - you're not allowed to say "such-and-such a project sucks because it's buggy!" when you haven't told the developers about the bug you're experiencing!</p>
<p>Filing issues also takes very little time and is super helpful to the developer. Probably a lot of the people who read this blog are software developers, so I'm betting you can understand how great it is to receive an issue that gives you lots of details that you can then use to fix a bug or a design problem. So why not give the gift of issues? Just make sure to search for duplicates! (This accounts for a significant amount of those 2,000 contributions on my GitHub profile. Over the course of my time on GitHub, I've filed 619 issues, 438 of which were on other people's projects. Of course, that's just on GitHub - I also do this frequently <em>outside</em> of GitHub.)</p>
<p>Again, every time you find yourself saying, "why doesn't it..." or "I wish it..." or "it's so annoying when...", let the developer know! You'll help them make their project better.</p>
<p>  [3]: this is not to suggest that you file ridiculous issues that don't really say anything or just complain. But a focused bug report describing something concrete that's problematic is awesome.</p>
<h2>Publish by default</h2>
<p>This is the last and biggest habit I have that I think led to those 2k contributions: I publish everything by default, no matter what. It doesn't matter how bad or hacky or ugly I think a software project is, I just publish it. Because honestly, why not?</p>
<p>Keeping projects public doesn't get in anyone's way. It's not like someone will look at your GitHub and be <em>annoyed</em> that you give so much software to the world. And there's even a chance that your hacky script may actually be <em>useful</em> to someone. Even if I think a project is "bad" I'll still publish it because the reality is that no one is going to go around GitHub specifically trying to find people to make fun of.</p>
<p>Publishing projects also gives me incentive to clean them up - write a README, write tests, and keep a change log (if relevant). My standards are higher because I know all my work is all in the open - not because I'm afraid of other people telling me I'm doing it wrong, but because I want to create high quality code that has a better chance of being useful to the wider community.</p>
<h2>In summary</h2>
<p>All of these habits are related. The tl;dr is this: engage by default. Get used to being involved instead of shrugging off a problem and moving on. Put your work out there for other people to see. The open source/freedom-respcting software community belongs to everyone - and that means we can all contribute to improving it. We just have to start.</p>
]]></description><link>https://strugee.net/blog/2017/02/how-i-passed-2k-github-contributions</link><guid isPermaLink="true">https://strugee.net/blog/2017/02/how-i-passed-2k-github-contributions</guid><category><![CDATA[personal]]></category><category><![CDATA[development]]></category><category><![CDATA[tips]]></category><category><![CDATA[blaggregator]]></category><pubDate>Thu, 23 Feb 2017 12:46:19 GMT</pubDate></item><item><title><![CDATA[From static to Stratic - part 1]]></title><description><![CDATA[<p>So a couple days ago I published <code>generator-stratic@1.0.0-beta.1</code> to npm. Since Stratic is now officially in beta, I thought I'd write up a guide to converting a regular, static site to a Stratic-powered blog.</p>
<p>Each step in this blog post (part 1 of 2[?]) will take you closer to having a fully-functional blog, but because of Stratic's decoupled design, you can work through them at your own pace. Each step will leave you with a functional environment (i.e. nothing will be "broken" such that you can't work on your website anymore).</p>
<p>You can see the steps in this post in action at <a href="https://github.com/straticjs/static-to-stratic">straticjs/static-to-stratic</a>. Each commit corresponds to a step in this post.</p>
<p>Let's get started!</p>
<h2>Initial setup</h2>
<p>The site we'll be converting is currently pretty simple. It has an <code>index.html</code> and a <code>projects.html</code>. Each of these includes <code>/css/main.css</code> and <code>/js/main.js</code>. Also, they both have a navigation section and a footer that are duplicated across each page. Each time Alyssa P. Hacker - the website's owner - makes a change to these (for example to fix the copyright year in the footer), she has to change both HTML files. The best way for her to add a new page will be to copy an existing HTML file and then change it. This is a little unideal.</p>
<p>Alyssa tracks her website on GitHub (in the example repository mentioned above). Here are links for the <a href="https://github.com/straticjs/static-to-stratic/blob/18a7a7da03a2f84f525f0b699a43005067428199/index.html"><code>index.html</code></a> and the <a href="https://github.com/straticjs/static-to-stratic/blob/18a7a7da03a2f84f525f0b699a43005067428199/projects.html"><code>projects.html</code></a> we'll be working with.</p>
<p>Here's a visual of the project layout:</p>
<pre><code>% tree .
.
âââ css
â&nbsp;&nbsp; âââ main.css
âââ index.html
âââ js
â&nbsp;&nbsp; âââ main.js
âââ projects.html

2 directories, 4 files
</code></pre>
<p>When Alyssa needs to preview her website, she manually runs <code>http-server .</code>.</p>
<p>Since Alyssa uses GitHub she publishes her website on GitHub Pages, so her website is in the <code>master</code> branch of her git repository. (Here we're assuming that the repository is called <code>aphacker.github.io</code> or something, instead of <code>static-to-stratic</code>.)</p>
<p>In addition to adding blog support, we'll improve Alyssa's website by reducing duplication while still allowing her to publish to GitHub Pages.</p>
<h2>Step 1 - adding gulp</h2>
<p>Before we do anything else, we need to add a build system. Stratic is designed to work with <a href="https://strugee.net/blog/">gulpjs</a>, so that's the one we'll be using.</p>
<p>Adding gulp is super easy. First, we need to create a <code>package.json</code>, so we do <code>npm init</code>:</p>
<pre><code>% npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sensible defaults.

See `npm help json` for definitive documentation on these fields
and exactly what they do.

Use `npm install &lt;pkg&gt; --save` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
name: (static-to-stratic)
version: (1.0.0)
description: Personal website of Alyssa P. Hacker
entry point: (index.js)
test command:
git repository: (https://github.com/straticjs/static-to-stratic.git)
keywords:
author: Alyssa P. Hacker &lt;alyssaphacker@example.net&gt;
license: (ISC) AGPL-3.0+
About to write to /Users/alex/Development/static-to-stratic/package.json:

{
  "name": "static-to-stratic",
  "version": "1.0.0",
  "description": "Personal website of Alyssa P. Hacker",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/straticjs/static-to-stratic.git"
  },
  "author": "Alyssa P. Hacker &lt;alyssaphacker@example.net&gt;",
  "license": "AGPL-3.0+",
  "bugs": {
    "url": "https://github.com/straticjs/static-to-stratic/issues"
  },
  "homepage": "https://github.com/straticjs/static-to-stratic#readme"
}


Is this ok? (yes) yes
</code></pre>
<p>A couple things to note here: in general, the defaults are fine to accept. We've provided a description and an author, but these are optional since this isn't actually going to be published on the npm registry. They're just kind of nice to have.</p>
<p>The same goes for the license, which in this case is the <a href="https://www.gnu.org/licenses/agpl-3.0.en.html">Affero GPL 3.0 or above</a> - however, as the copyright holder you are of course free to <a href="https://choosealicense.com/">choose whatever license</a> you want. (Or no license, although I'd discourage you from doing that.)</p>
<p>Once we have a <code>package.json</code>, we can go ahead and install gulp and another module we'll need, <code>ecstatic</code>:</p>
<pre><code>% npm install --save-dev gulp ecstatic
</code></pre>
<p>If you haven't used gulp previously, you'll also need to install <code>gulp-cli</code>:</p>
<pre><code>% npm install -g gulp-cli
</code></pre>
<p>At this point, we'll need to move some files around. Now that we have a build system, we can organize our repository however we want instead of putting stuff exactly where we want it in production.</p>
<p>You can do this however you want. The organization that you'll find most projects using, though, is to put stuff in a <code>src</code> directory. Let's make that right now.</p>
<pre><code>% mkdir src
% git mv *.html src
% git mv css src/styles
% git mv js src/scripts
</code></pre>
<p>Finally, create a file named <code>gulpfile.js</code> and put the following in it:</p>
<pre><code>var gulp = require('gulp'),
    http = require('http'),
    ecstatic = require('ecstatic');

gulp.task('build:html', function() {
    gulp.src('src/*.html')
        .pipe(gulp.dest('dist'));
});

gulp.task('build:css', function() {
    gulp.src('src/styles/*')
        .pipe(gulp.dest('dist/css'));
});

gulp.task('build:js', function() {
    gulp.src('src/scripts/*')
        .pipe(gulp.dest('dist/js'));
});

gulp.task('watch', ['build'], function() {
    gulp.watch('src/*.html', ['build:html']);
    gulp.watch('src/styles/*', ['build:css']);
    gulp.watch('src/scripts/*', ['build:js']);
});

gulp.task('serve', ['watch'], function() {
        http.createServer(
                ecstatic({ root: __dirname + '/dist' })
        ).listen(8080);
});

gulp.task('build', ['build:html', 'build:css', 'build:js']);

gulp.task('default', ['serve']);
</code></pre>
<p>This gives us a pretty good starting point. This gulpfile defines a couple tasks that simply copy source files into <code>dist</code>. The <code>watch</code> task watches for changes and rebuilds when they occur, and the <code>serve</code> task starts up a server, replacing Alyssa's usage of <code>http-server</code>. This provides exactly the same workflow as before: Alyssa runs one command and then she can look at her site on <code>localhost:8080</code>. You can use different task names if you want (for example, <code>html</code> instead of <code>build:html</code>, etc.), but these are what <code>generator-stratic</code> gives you.</p>
<p>However, there's one problem: Alyssa can't deploy her site anymore. If she pushed like this, visitors would have to visit e.g. <code>https://aphacker.github.io/src/projects</code> instead of <code>https://aphacker.github.io/projects</code>! That's no good.</p>
<p>In order to rectify this, we'll create a new git branch, <code>src</code>. <code>src</code> will contain the source files, and we'll put the final, built site in <code>master</code>, which is what's served by GitHub Pages. So:</p>
<pre><code>% git checkout -b src
% git push --set-upstream origin src
</code></pre>
<p>Great. Now, we need to add something to put the built files (i.e. the contents of <code>dist</code>) in <code>master</code>. We'll use the <code>gh-pages</code> module for this. First install it and a dependency we'll need:</p>
<pre><code>% npm install --save-dev gh-pages gulp-util
</code></pre>
<p>Next, make it available in the gulpfile by adding a line at the end of <code>require()</code> statements:</p>
<pre><code>var gulp = require('gulp'),
    http = require('http'),
    ecstatic = require('ecstatic');
</code></pre>
<p>And finally, add a <code>deploy</code> task somewhere in the gulpfile:</p>
<pre><code>gulp.task('deploy', ['build'], function(done) {
    ghpages.publish(path.join(__dirname, 'dist'), { logger: gutil.log, branch: 'master' }, done);
});
</code></pre>
<p>Now whenever Alyssa wants to deploy a new version of her website, she just runs <code>gulp deploy</code> and it'll be taken care of for her. (ProTipâ¢: change the default branch to <code>src</code> on GitHub. That way visitors and new clones see the source files, not the build files generated by a program.)</p>
<p>The very last thing we need to do is add a <code>.gitignore</code> file since we're installing Node modules and have a build directory now. We'll just use GitHub's, adding a line for <code>dist/</code> at the end:</p>
<pre><code>% curl https://raw.githubusercontent.com/github/gitignore/master/Node.gitignore &gt; .gitignore
% echo "\ndist/\n" &gt;&gt; .gitignore
</code></pre>
<p>Now we've got a functionally equivalent development setup based on gulp. Success!</p>
<h2>Step 2: converting HTML to Pug</h2>
<p>The next step is to convert the HTML to <a href="https://pugjs.org">Pug</a>. Pug (formerly known as Jade) is a language that compiles to HTML. It lets you do useful things like inherit from a common layout as well as looping over JavaScript variables. If you're not familiar with Pug, you should go take a look at its syntax now.</p>
<p>The easiest way to do this conversion is to get a program to do it for you. <a href="http://html2jade.aaron-powell.com/">Here's the one I used</a> way back when; you may be able to find a better one. The generated Pug will be valid but not the prettiest - you may want to wait to clean it up since we're going to do some work to reduce the duplication soon.</p>
<p>Once you've got the converted Pug, you should rename the relevant HTML file to have a <code>.pug</code> extention, then replace the contents with the Pug. Do this for each HTML file.</p>
<p>The last step here is to make gulp build the Pug. Install <code>gulp-pug</code>:</p>
<pre><code>% npm install --save-dev gulp-pug
</code></pre>
<p>Then add <code>pug = require('gulp-pug')</code> to the end of the <code>var</code> declaration at the top of your gulpfile. Finally, change your <code>html</code> task to look like this:</p>
<pre><code>gulp.task('build:html', function() {
    gulp.src('src/*.pug')
        .pipe(pug({pretty: true}))
        .pipe(gulp.dest('dist'));
});
</code></pre>
<p>We'll also need to fix the <code>watch</code> task so it has:</p>
<pre><code>gulp.watch('src/*.pug', ['build:html']);
</code></pre>
<p>which will watch Pug files instead of HTML files.</p>
<p>That's it! Alyssa's site is now building with Pug instead of HTML.</p>
<h2>Step 3: splitting out the layout</h2>
<p>Pug's looping and flow control constructs will be very useful to us later on, but we can get some immediate productivity wins by splitting out the site layout so it's not duplicated across every Pug file.</p>
<p>There's one tricky thing about this: the navigation is mostly the same between pages, but not quite - the page the user is currently on shouldn't be a link. We'll solve this by using a <code>block</code> directive for each link. That way, we can override just what needs to be changed, while introducing no duplication.</p>
<p>You'll have to figure out exactly what parts of your personal layout make sense to be split out. In Alyssa's case, there are three main things that are mostly or fully duplicated across pages:</p>
<ol>
<li>The navigation bar</li>
<li>The footer</li>
<li>Invisible metadata and script/style includes</li>
</ol>
<p>These are what we'll split out. First, we'll make a copy of <code>index.pug</code> and put it in <code>src/includes/layout.pug</code>. (Again, you can organize your files however you want - but in projects generated by <code>generator-stratic</code>, utility Pug files go in <code>src/includes</code>.) Next, edit out the page-specific content and replace them with <code>block</code> directives. Finally, edit each navigation bar item so it has its own <code>block</code> directive, leaving the old code as the default for the <code>block</code> directive.</p>
<p>Here's what this looks like when we do this to Alyssa's site:</p>
<pre><code>doctype html
html
  head
    meta(charset='UTF-8')
    link(href='/css/main.css', rel='stylesheet', type='text/css')
    block head
  body
    block heading
    nav
      ul
        block nav-homepage
          li
            a(href='/') Homepage
        block nav-projects
          li
            a(href='/projects') Projects

    block body

    footer
      p &amp;copy; Copyright 2016 Alyssa P. Hacker.
    script(src='/js/main.js', type='text/javascript')
</code></pre>
<p>Note how I've replaced the <code>h1</code> element (the contents of which vary per-page) with <code>block heading</code>, I've added a <code>block head</code> directive so we can specify the title per-page, I've made a <code>block</code> for each navigation link so we can override them if we want to individually (otherwise they'll have the default of being a link), and I've added <code>block body</code> for the main content. I've also cleaned out a bunch of the cruft the automatic converter put in there.</p>
<p>Now, we can edit <code>index.pug</code> so that it inherits from <code>layout.pug</code> - we'll use the <code>extends</code> keyword for this. Then we just fill in the content we want using block. Here's what this looks like after we're finished with Alyssa's site:</p>
<pre><code>extends includes/layout.pug

block head
  title Alyssa P. Hacker's homepage

block heading
  h1 Alyssa P. Hacker's homepage

block nav-homepage
  li Homepage

block body
  p This is the homepage of Alyssa P. Hacker. You can check out the projects I've worked on #[a(href='/projects') here].
</code></pre>
<p>You'll note that I've cleaned out some cruft here, too. We have one last thing to fix: if we change the layout, nothing will get rebuilt. We can fix this by changing the <code>watch</code> task again so that the line for watching Pug files reads:</p>
<pre><code>gulp.watch(['src/*.pug', 'src/includes/*.pug'], ['build:html']);
</code></pre>
<p>Sweet! <code>index.pug</code> is way shorter than what we had before and includes <em>just</em> the content now. We can do the same thing to <code>projects.pug</code>. Then Alyssa can, for example, correct the copyright year in <code>layout.pug</code> - i.e., once - and that change will go into both <code>index.html</code> <em>and</em> <code>projects.html</code>. I've gone ahead and made the change for her.</p>
<p>To give a high-level overview, here's what Alyssa's site looks like now:</p>
<pre><code>% tree -I node_modules .
.
âââ dist
â&nbsp;&nbsp; âââ css
â&nbsp;&nbsp; â&nbsp;&nbsp; âââ main.css
â&nbsp;&nbsp; âââ index.html
â&nbsp;&nbsp; âââ js
â&nbsp;&nbsp; â&nbsp;&nbsp; âââ main.js
â&nbsp;&nbsp; âââ projects.html
âââ gulpfile.js
âââ package.json
âââ src
    âââ includes
    â&nbsp;&nbsp; âââ layout.pug
    âââ index.pug
    âââ projects.pug
    âââ scripts
    â&nbsp;&nbsp; âââ main.js
    âââ styles
        âââ main.css

7 directories, 11 files
</code></pre>
<h2>Next time...</h2>
<p>This post is long enough already, so I'll stop here. We've converted Alyssa's site to have a really solid base, so next time we'll build on top of this work to add superpowered blog features, powered by Stratic.</p>
<p>Now go apply this to your own site!</p>
]]></description><link>https://strugee.net/blog/2017/02/from-static-to-stratic-part-1</link><guid isPermaLink="true">https://strugee.net/blog/2017/02/from-static-to-stratic-part-1</guid><category><![CDATA[development]]></category><category><![CDATA[stratic]]></category><category><![CDATA[blaggregator]]></category><pubDate>Mon, 20 Feb 2017 14:58:53 GMT</pubDate></item><item><title><![CDATA[RSS and pagination on strugee.net]]></title><description><![CDATA[<p>RSS and pagination are now enabled on strugee.net's blog, thanks to <a href="https://github.com/strugee/stratic-indexes-to-rss">stratic-indexes-to-rss</a> and <a href="https://github.com/strugee/stratic-paginate-indexes">stratic-paginate-indexes</a> respectively.</p>
<p>The pagination code is already pretty solid although there's always room for <a href="https://github.com/strugee/stratic-paginate-indexes/issues">improvement</a> - thanks to <a href="https://github.com/atungare">Ajay Tungare</a> for pairing with me at the <a href="https://recurse.com">Recurse Center</a> and helping me catch the bug! However, I'm not particularly confident in the RSS code, since RSS is actually somewhat tricky to properly handle. Because of that, I would seriously appreciate it if people tried adding the RSS feeds to their readers and seeing if anything breaks. If so, <a href="https://github.com/strugee/stratic-indexes-to-rss/issues/new">let me know</a>!</p>
<p>Cheers!</p>
]]></description><link>https://strugee.net/blog/2017/01/rss-and-pagination-on-strugee.net</link><guid isPermaLink="true">https://strugee.net/blog/2017/01/rss-and-pagination-on-strugee.net</guid><category><![CDATA[development]]></category><category><![CDATA[blaggregator]]></category><pubDate>Tue, 10 Jan 2017 13:48:01 GMT</pubDate></item></channel></rss>